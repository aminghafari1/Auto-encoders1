{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## building an auto-encoder class\n",
    "## builiding the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model \n",
    "from keras.layers import Input, Conv2D\n",
    "\n",
    "class Autoencoder:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 conv_filters,\n",
    "                 conv_kernels,\n",
    "                 conv_strides,\n",
    "                 latent_space_dim):\n",
    "        self.input_shape = input_shape # [28,28,1] this means the input is a 28x28 image with 1 channel (grayscale) like mnist\n",
    "        self.conv_filters = conv_filters #[2,4,8] this means the first layer has two filters, the second 4, and the last 8.\n",
    "        self.conv_kernels = conv_kernels #[3,5,3] this means the first layer has a 3x3 kernel, the second 5x5, and the last 3x3.\n",
    "        self.conv_strides= conv_strides  #[1,2,2] this means the first layer has a stride of 1, the second 2, and the last 2.\n",
    "        self.latent_space_dim = latent_space_dim # 2 this means the bottleneck will only have 2 dimensions.\n",
    "        self.encoder= None\n",
    "        self.decoder = None\n",
    "        self.model= None\n",
    "        self._num_conv_layers= len(conv_filters)\n",
    "        self._build()\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers= self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self.encoder = Model(encoder_input, bottleneck, name='encoder')\n",
    "    \n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name='encoder_input')\n",
    "        \n",
    "    ## This will create all convolutional blocks in encoder    \n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        x= encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x   \n",
    "    \n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        layer_number= layer_index+1\n",
    "        ## Adds a convolutional block to a graph of layers, consisting of a conv 2d+ batch norm + relu \n",
    "        conv_layer = Conv2D(filters=self.conv_filters[layer_index],kernel_size=self.conv_kernels[layer_index],\n",
    "                            strides=self.conv_strides[layer_index], \n",
    "                            padding='same', name=f'encoder_conv_layer_{layer_number}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfc00275c037e0322d65458631b9d66cd4b1daeaa2d39a92fa6d181b0d340908"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
